---
title : "CS231n 5강 요약"
category :
    - CS231n
tag :
    - machine_learning
    - computer vision
    - CS231n
toc : true
toc_sticky: true
comments: true
---
Convolution Neural Networks에 대해서 알아보자!

## 0. Today's Goal
> - Convolution Layer에 대해서 알아보자.
> - 간단한 용어 정리

## 1. 강의 및 강의 자료

강의를 들어볼 수 있는 링크와 강의 자료를 pdf형식으로 준비했다.

- 강의 링크 : [video](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/4974868/cs231n_2017_lecture5.pdf)

한글 자막이 필요하신 분은 다음의 링크를 확인해주세요. :)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. 강의 요약

### Convolution Layer에 대해서 알아보자.

지난 시간에는 Neural Networks에 대해서 배웠는데, 선형 함수와 비선형 함수의 합으로 계속 이어져 있다는 것을 볼 수 있었다.

Convolution Neural Network의 큰 특징은 **공간적 구조를 유지**하는 layer를 가지고 있다는 점이다.

여기서 Convolution이라는 개념은 좀 더 rough하게 가져갈 필요가 있다. 우리가 신호처리에서 배운 개념과는 살짝 다른 식으로 적용이 된다!

Fully connected layer의 같은 경우, (32,32,3)의 이미지가 입력으로 들어오면,
(3072,1)의 형태로 만들어준 다음, 계산을 수행한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448205-2165bd80-ce76-11ea-8a36-f65adb211551.png" width = "500" ></p>

Convolution layer의 경우 Filter를 하나 만들고, 그 Filter가 움직이면서 Output을 만들어낸다.
필터를 $w$라고 했을 때, Output의 한 점은 $w^Tx + b$로 내적을 시킨 값을 넣어준다고 생각하면 된다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448287-368f1c00-ce77-11ea-924b-9f092707372b.png" width = "500" ></p>

하나의 Filter는 항상 입력의 채널의 수만큼 확장이 되어야 한다!


<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448405-a3ef7c80-ce78-11ea-87dd-b420861f0844.png" width = "500" ></p>


또한, <U>Filter의 수로 Output의 activation map의 수를 결정</U>할 수 있다!

**다른 Filter들로 같은 위치에서 다른 특징들을 뽑아 낼 수 있다!**

Convolution layer를 여러 번 수행하면 다음과 같이 나타낼 수 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448449-1b251080-ce79-11ea-92bb-779f5404cd08.png" width = "500" ></p>

<br>
입력을 이미지로 넣었을 때 각 layer마다 어떤 feature들이 뽑아질 수 있는지 다음의 예시를 참고하면 직관적으로 이해할 수 있다.

low-level 특징점부터 high-level 특징점까지 다양한 특징을 추출할 수 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448574-304e6f00-ce7a-11ea-9a1a-ab6f0047757b.png" width = "500" ></p>

### 간단한 용어 정리

#### Stride
- Stride : Filter가 입력 Image를 sliding할 때, 몇 칸씩 띄어가면서 계산을 할 것인가 알려주는 것.

예를 들면, Stride = 1일 때
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448836-b8357880-ce7c-11ea-9afb-c82382d169ba.png" width = "400" ></p>
Stride = 2일 때
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448854-d56a4700-ce7c-11ea-9e64-43660faa96df.png" width = "450" ></p>

#### Padding
- Padding : convolution 과정을 거치면 결과 activation map의 가로,세로가 줄어들게 되는데, Input Size를 유지하고 싶어서 Image 가장자리에 값을 채워주는 것. 여기서는 zero padding을 예로 들었다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448892-4ad61780-ce7d-11ea-8768-1de2abd14432.png" width = "500" ></p>

#### Pooling

- Pooling : 강제로 downsampling을 하고 싶을 때, 사용하는 기법. depth에는 영향을 주지 않는다. 파라미터의 수를 줄어들게 하는 효과가 있다. 주로 Maxpooling이라는 기법을 많이 사용한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88448931-c932b980-ce7d-11ea-9a22-5b2e7dbbf874.png" width = "400" ></p>

---

강의가 약간 Preview 형식이라 간단하게 설명을 했던 것 같다.

Convolution layer를 여러개 사용하고 Fully connected layer를 마지막에 사용하면 CNN 딥러닝 모델이 만들어 진다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/88449000-5249f080-ce7e-11ea-95fc-6da9fceb4ec8.png" width = "500" ></p>
