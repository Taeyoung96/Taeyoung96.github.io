---
title : "CS231n 3강 요약"
category :
    - CS231n
tag :
    - machine_learning
    - computer vision
    - CS231n
toc : true
toc_sticky: true
comments: true
---

오늘은 loss functions와 optimization에 대해 배워보자!!

## 0. Today's Goal
> - Loss function에 대해서 알아보자.
> - Regularization이란?
> - Softmax vs SVM
> - Optimization에 대해서 알아보자.

## 1. 강의 및 강의 자료

강의를 들어볼 수 있는 링크와 강의 자료를 pdf형식으로 준비했다.

- 강의 링크 : [video](https://www.youtube.com/watch?v=h7iBpEHGVNc&t=2096s)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/4910668/cs231n_2017_lecture3.pdf)

한글 자막이 필요하신 분은 다음의 링크를 확인해주세요. :)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. 강의 요약

### Loss function에 대해서

Loss function을 번역하면 '손실 함수'이다. 앞선 강의에서 weight에 대한 개념을 잡았다. 손실함수는 <U>weight를 입력으로 받아서 weight의 결과가 정답 값과 얼마나 차이가 나는지 보여주는 역할</U>을 한다.

손실 함수에도 여러가지 종류가 있는데 우선 우리가 알아볼 손실 함수는
**Multiclass SVM loss**이다.

**Multiclass SVM loss**는 각 클래스에 대한 점수를 매겼을 때,
**그 점수(score)가 정답과 얼마나 차이가 나는지만 관심이 있는 함수**이다.


예시를 통해 알아보면 만약 분류해야 할 클래스가 3개이고  
$f(x,W) = Wx$라는 함수를 사용해서 클래스에 대해 점수를 매긴다고 하자.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87272775-3b1c1200-c512-11ea-8d41-2dada5c5d8de.png" width = "400" ></p>

각 항에 숫자가 의미하는 것은 분류기를 통해 예측한 클래스별 점수이다.
이 분류기(function)의 경우 자동차에 대해서는 잘 분류를 하지만, 다른 그림에 대해서는 분류를 잘 하지 못하는 것이라고 볼 수 있다.

그렇다면 <U>이 분류기가 얼마나 분류를 잘하는지 알아보기 위해
Loss function을 이용하여 수치화</U>를 한다.

우리는 얼마나 분류기가 잘 분류하는 건지 알아보고 싶은건데,
공식을 이용하여 수식으로 표현하면

$L=\frac1N\sum_iL_i(f(x_i,W),y_i)$

- $L_i$는 사용할 loss function
- $f(x_i,W)$는 내가 분류기를 사용해서 나온 클래스의 점수
    위 그림에서는 3.2, 5.1, -1.7 같은 숫자들..
- $y_i$는 실제 클래스의 정답 값 (맨 왼쪽의 고양이 이미지의 경우 3.2)
- $N$은 클래스의 수 (여기서는 3이 된다.)

어떤 $L_i$를 쓰는 것인가에 따라 또 $L$의 값이 달라진다.

우리는 처음에 Loss function을 **Multiclass SVM loss**로 설계했으므로
이에 대해 Loss function을 다음과 같이 식으로 표현할 수 있다.

$L_i=\sum_{j \neq y_i}max(0,s_j-s_{y_i}+1)$

- $s_j$는 분류기를 통해 예측한 각 클래스별 점수(score)
- $s_{y_i}$는 해당 클래스의 정답 점수(score)
- 1은 'safty margin', 예측 값과 정답 값에 대한 상대적인 차이를 주기 위해 설정

**Multiclass SVM loss**를 그래프로 그려보면

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274369-951ed680-c516-11ea-8b0d-73950b02eea7.png" width = "400" ></p>

정답 클래스를 가장 높은 점수를 매긴다면 $L_i$의 값은 0에 가까울 것이고,
그렇지 않다면 Loss의 값이 크게 오를 것이다.

앞선 예시에서 Loss의 값을 계산한다면,

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274536-edee6f00-c516-11ea-9da1-6f1701491589.png" width = "150" ></p>

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274812-9ef50980-c517-11ea-88b3-a80a1a88f3c3.png" width = "300" ></p>

이런 식으로 계산을 할 수 있다. 
차례대로 car 클래스와 frog 클래스에 대해서도 Loss를 계산할 수 있다.

여기서 **Multiclass SVM loss**에 대해 몇가지 질문을 던지는데..

> - Q1 : car score이 변하게 된다면 loss의 값은 어떻게 되는가?
> - Q2 : loss값의 최솟값과 최댓값을 구하면?
> - Q3 : 초기에 W가 0에 가까우면 모든 score의 값은 0과 비슷하다. 
    이때 loss값을 구하면?
> - Q4 : $L_i$값을 구하는데 합을 구할 때 ${j \neq y_i}$가 아닌, $j$를 포함한 모든 값을 다 더하게 되면?
> - Q5 : Loss를 계산하는데, 합 대신 평균을 사용하면 Loss값은 어떻게 되는가?
> - Q6 : 손실 함수를 $max(0,s_j - s_{y_i} + 1)$가 아닌 $max(0,s_j - s_{y_i} + 1)^2$을 사용하게 된다면?

모두 다 심오한 질문들이다...

친절하게 모든 질문에 답을 해준다.

> - A1 : score 간에 상대적인 차이가 중요하므로 loss의 값에는 크게 영향을 미치지 않는다.
> - A2 :  그래프를 생각해본다면 최솟값은 0 , 최댓값은  $\infty$ 이다.
> - A3 : Loss는 '(클래스) - 1'이 된다. 이는 디버깅할 때 유용한 팁이 된다.
> - A4 :  $j$를 포함한 모든 값을 다 더하게 되면 Loss의 값이 '0'이 아닌 '1'이 정답 값이다. 
(정답이라는 표현이 애매한데 오차가 없으면 Loss 값이 1로 나온다.)
> - A5 : Loss 값을 구하는데는 크게 상관이 없다. 우리가 관심이 있는건 정답 클래스의 점수와 그렇지 않은 클래스의 차이이기 때문이다.
> - A6 : 손실 함수를 계산하는 것 자체가 변하기 때문에 값이 완전히 달라진다.


여기서 또 질문...

**우리가 Loss function을 이용해서 L을 구했을 때 L = 0 인 W의 값이 단 하나인가?**

답은..
> 또 다른 W의 값이 존재한다.

그렇다면 **수 많은 W의 값들 중에서 우리가 선택해야하는 W의 값은?**

답은..
> train data를 이용해서 어떤 분류기를 찾고 (즉, W의 값을 찾고) 이 분류기(W)를 test data에 적용했을 때 성능이 잘 나오는 것을 고르면 된다!

그렇다면

어떻게 우리가 원하는 W의 값을 찾는가?

여기서 **Regularization**의 개념이 나온다.

---

### Regularization이란?

간단히 말하면 Regularization이란 training set에 model이 완벽하게 fit하지 못하도록 모델의 복잡도에 페널티를 부여하는 것을 말한다.

우리가 train data로 model을 만든다면, 

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87305171-024f5d80-c551-11ea-9cb6-2ccaf6174f76.png" width = "300" ></p>

이런 파란색 그래프를 예측할 수 있다. 

하지만 만약에 우리가 원하는 model이 초록색 그래프와 같다면?

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87305324-417dae80-c551-11ea-96dc-d83f417383db.png" width = "300" ></p>

우리가 원하는 model은 좀 더 단순화한 model (즉, overfitting이 일어나지 않는 model)이다. 
이런 model을 만들기 위해 사용하는 것이  **Regularization**이다.

즉, 수식으로 쓰면 다음과 같다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/94806968-dc3baa00-0429-11eb-8984-e848e0b9129d.png" width = "400" ></p>


여기서 $\lambda R(W)$ 부분이 **Regularization**이다.

Regularization 종류에는 여러가지가 있는데,

1. L1 regularization
2. L2 regularization
3. Max norm regularization
4. Dropout
5. Batch Normalization 등등...

L2 regularization을 예로 들어 보면,

$x = [1,1,1,1]$ 이라는 data가 있을 때
$w_1 = [1,0,0,0]$ , $w_2 = [0.25,0.25,0.25,0.25]$가 있다고 하자.

$f(x) = Wx$라 할 때, $w_1^Tx = w_2^Tx = 1$로 같다.

따라서 $\lambda R(W)$을 추가하여 penalty를 주게 되는데
이 예제에서는 $w_2$의 $R(W)$ 값이 $w_1$의 $R(W)$값보다 크므로
문제에서 $w_2$이 좀 더 적합한 Weight로 채택했다고 볼 수 있다.

---

### Softmax vs SVM

우리가 지금까지 Loss function을 설명할 때,
Multi class SVM을 예시로 설명을 하였다.

또 하나의 Loss function을 소개하는데, 그것은 바로 **Softmax**이다.

두 함수의 가장 큰 차이점은 **Multi class SVM** 같은 경우 <U>정답 score과 오답 score(정답 클래스가 아닌 다른 클래스)의 차이(Gap)에만 관심</U>을 보였다면,
**Softmax**의 경우 <U>그 차이를 모두 수치화하여 score에 대한 해석</U>을 할 수 있도록 한다.

**Softmax**를 구하는 방법은
> 1. 먼저 각 클래스에 대해 score를 먼저 구한다.
> 2. 모든 클래스의 score를 구하고 각 클래스마다 score를 구하여 확률에 대한 식으로 바꾸어 준다. (unnormalized probabilities)
> 3. 정규화를 통해 score값을 0 ~ 1사이로 바꾸어준다.

수식을 통해 Softmax를 알아볼 경우 다음과 같다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/94807056-ff665980-0429-11eb-8462-2519eb115a11.png" width = "300" ></p>

- $s_j$는 분류기를 통해 예측한 각 클래스별 점수(score)
- $s_{y_i}$는 해당 클래스의 정답 점수(score)
- 지수형을 쓴 이유는 모두 양수로 만들기 위함이다.

한 장의 그림으로 정리하면 다음과 같다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87333393-0347b580-c578-11ea-9a0a-903e7d30f1a4.png" width = "550" ></p>

지금까지 Loss function과 Regularization에 대해서 배웠는데
<U>궁극적으로 우리가 원하는 것은 최적의 W를 찾는 것이다.</U>

---

### Optimization에 대해서

최적의 W를 찾으려면 어떻게 해야할까?

단순하게 생각해보면 random search를 이용하여 임의의 W를 선택하는 방법이 있다. (~~하지만 실제로 이렇게 하면 안됨..~~)

다음으로는 **기하학적인 특징을 활용**하는 것이다.

어떠한 점에서 gradient를 구한다면 이 점에서 Loss값에 대한 기울기를 구할 수 있다.

다시 말해 어떤 점 A에서 gradient값이 -5, 점 B에서 gradient값이 0.1이라면 두 점 중에서는 점 B를 이루는 Weight가 최적의 weight에 가깝다는 의미이다.

이러한 최적화 방법을 **Gradient Descent**라고 한다.

처음에 weight를 초기화 시키고, loss와 gradient를 계산하여 weight의 값을 gradient 반대 방향으로 update를 계속 시켜주는 것을 말한다.

하지만 모든 data에 대하여 일일이 이 작업을 하기에는 연산량이 너무 많다.

따라서 우리는 묶음(minibatch)를 활용해 Gradient Descent를 사용하는데 이를 **Stochastic Gradient Descent(SGD)**라고 한다.

**Stochastic Gradient Descent(SGD)**에 대한 식은 다음과 같다.
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87335300-05f7da00-c57b-11ea-90c2-cac9ed48fcd2.png" width = "400" ></p>

minibatch에는 보통 $2^n$을 사용한다.

---

### Image features vs ConvNets

최근 Image classification에 대한 연구는 두가지 방향으로 이루어진다.

> - 첫번째는 특징 표현을 계산하고 미리 찾은 다음 Linear Classifier에 입력으로 넣어주는 방법
> - 두번째는 입력 이미지 자체를 Neural Networks의 넣어주는 방법

두 가지 방법의 가장 큰 차이점은 <U>특징을 뽑아내는 추출자(Feature Extractor)를 고정할 것인가, 그렇지 않은가에 있다.</U>

특징을 뽑아내는데 주로 사용하는 방법은
- Color Histogram
- Histogram of Oriented Gradients (HOG) : 주된 edge의 방향에 대한 정보를 얻고 싶을 때 사용한다.
- 좌표계를 바꿔서 특징을 추출하기도 한다.

여러가지 방법들이 있지만 이 강의에서는 크게 3가지에 대해 언급했다.

---

이렇게 3장의 강의를 요약했다... 

아직 시작도 안했는데

양이 너무 많아진 느낌이다.















