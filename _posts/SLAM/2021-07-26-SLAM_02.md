---
title : "Slam 2강 (Least Squares - An Informal Introduction) 요약"
category :
    - Slam
tag :
    - Slam
toc : true
toc_sticky: true
comments: true
---

SLAM 강의를 듣고 정리해보자!  

## 0. Today's Goal

- Least Squares란?  
- Gauss-Newton Method    
- Least Squares와 Probabilistic State Estimation의 관계  

## 1. 강의 및 강의 자료  

강의 List는 [SLAM KR](https://www.youtube.com/channel/UCXvT7auo7xUd7v0B2pmvwIA)의 SLAM DUNK seson 2에서 정해준 강의를 따라 정리를 할 것이다.  

SLAM DUNK season 2의 목차는 [여기](https://youtube.com/playlist?list=PLubUquiqNQdMYwQVftUSFEWhJgzBErO9N)서 확인해 볼 수 있다.  

SLAM KR에서 이 강의를 듣고 요약을 세미나 형식으로 준비를 해준다!

이번 포스팅은 다음의 강의들을 참고하여 요약을 해보았다.  

- [Least Squares - An Informal Introduction (Cyrill Stachniss)](https://youtu.be/r2cyMQ5NB1o)    
- [SLAM DUNK Season 2 - An Informal Introduction to Least Squares](https://youtu.be/mY3G_hjrt7A)  

Cyrill Stachniss의 강의 자료는 pdf로 [다운](https://drive.google.com/file/d/10d4lTskz_vZ5Buf4wyKhZiaeehA_YTPh/view?usp=sharing) 받을 수 있다.  

## 2. Least Squares란?  

Least Squares란 무엇일까?  

우리가 배우는 SLAM system은 **"Graph-based SLAM system"** 인데,  
SLAM system 중 backend에서 최적화를 수행하는 도구로 사용하는 것이 Least Squares이다.  

좀 더 일반적인 관점에서 Least Squares를 정의하자면,  
> 우리가 어떤 식에서 구해야 할 parameter보다 더 많은 관찰값(Observations)가 존재할 때, 그 관찰값들은 매번 Noise가 존재할 수 있다. 이런 경우 정확한 parameter값을 구하는데 error가 최소화되도록 구하는 방법이다. 그 error는 보통 관찰값과 추정값의 제곱으로 표현한다.    

다시 말하면, 어떤 식에서 구해야할 parameter가 4개일 때, 이 parameter를 구하기 위해 실험을 진행할 것이고, 이 때 실험을 5번 진행되어 관찰되는 값이 parameter보다 많을 때 정확한 parameter 값을 구하기 위하여 사용하는 최적화 방법이 바로 **Least Squares** 이다.  

Least Squares에 대한 자세한 설명이 필요하다면 [최소자승법 이해와 다양한 활용예 (Least Square Method) - 다크프로그래머](https://darkpgmr.tistory.com/56) 포스팅을 참고하면 될 것이다.  

Least Squares는 선형화를 가정하여 error의 최소화를 구하는 방법인데,  
만약 Non-linear한 모델일 경우, 사용하는 방법 중 하나가 **Gauss-Newton Method**이다.  

그럼 강의에서는 Least Squares의 예를 어떻게 들었는지 Least Squqres를 통해 구하려는 것이 무엇인지 또한 필요한 가정에는 어떤 것이 있는지 설명을 해보도록 하겠다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/127118490-95db2044-f9e6-4c41-abfc-996c277a0bfd.png" width = "700" ></p>  


위 강의 자료를 통해 알 수 있듯이, Observation function $ \{f_i (x)\}_{i=1:n} $ 이라고 주어졌을 때,  

$z_{1:n}$ 에는 Noise가 존재하고, 최종적으로 $x$ 의 상태를 추정하는 것이 목표이다.  

Least Squqres에서는 error의 값을 예측값과 관찰값의 차이의 제곱으로 설정을 한다.  

이 예제에서는 $i$번째 관찰을 했을 때 예측값이 $\hat{z_i} = f_i (x)$ 그리고 실제 관찰값이 $z_i$이므로 이 두 값의 차에 의해 Error function을 만들 수 있다.  

따라서 error function은 $e_i(x) = z_i - f_i (x)$ 로 쓸 수 있고, 이 때 $e_i(x)$ 는 **Vector** 이다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/127121697-c03c6484-1123-4cea-a3e8-02e2da5a7e56.png" width = "500" ></p>  

좌측에 있는 $e_i (x)$의 경우 **Scalar 값** 으로 $i$번째 error function의 값이고,  
우측에 있는 $e_i (x)$의 경우 이전에 정의한 **Vector 값** 이다.  

위 식에서 $\Omega_i$는 information matrix를 표현한 것인데, 관찰 값에도 노이즈가 존재하여 이를 평균이 0이고, 정규 분포를 따르는 가우시안 확률로 error가 있다고 가정하기 때문에 이를 표현하기 위해서다.  

Error function을 이용해 우리가 구해야 할 것은 **error를 최소화 하는 x 값** 이다.  

아래의 식에서는 $x^{*}$ 라고 표현했다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/127125458-fee4a486-42bd-4baf-a4c5-c25de481781c.png" width = "700" ></p>  

단, 이 과정으로 최적의 해를 찾을 때는 <font color='#ff0000'> 중요한 가정 (Assumption) </font> 이 존재한다.  

- 초기에 setting한 값이 좋은 값이라는 가정  
- Error function을 이용하여 반드시 최적의 해를 찾는 것은 아니므로, 이를 이용하면 Global minima를 구할 수 있다는 믿음  

그렇다면 지금까지 구한 식을 이용하여 어떻게 최적의 state $x^{*}$ 를 찾을 수 있는지 그 중 한가지 방법인 Gauss-Newton method에 대해서 알아보자.









## 3. Gauss-Newton Method  

## 4. Least Squares와 Probabilistic State Estimation의 관계  

