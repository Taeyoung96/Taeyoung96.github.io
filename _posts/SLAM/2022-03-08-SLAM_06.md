---
title : "Slam 6강 (Bayes Filter) 요약"
category :
    - Slam
tag :
    - Slam
toc : true
toc_sticky: true
comments: true
---  

Cyrill 교수님의 SLAM 강의를 듣고 정리해보자! 

## 0. Today's Goal  

- Bayes Filter란?  
- Bayes Filter 식 유도  
- Bayes Filter의 개념적인 접근  
- Bayes Filter의 확장  
- Reference  


## 1. 강의 및 강의 자료  

강의 List는 [SLAM KR](https://www.youtube.com/channel/UCXvT7auo7xUd7v0B2pmvwIA)의 SLAM DUNK seson 2에서 정해준 강의를 따라 정리를 할 것이다.  

SLAM DUNK season 2의 Reference는 [여기](https://youtube.com/playlist?list=PLubUquiqNQdMYwQVftUSFEWhJgzBErO9N)서 확인해 볼 수 있다.  

SLAM KR에서 이 강의를 듣고 요약을 세미나 형식으로 준비를 해준다!  

이번 포스팅은 다음의 강의들을 참고하여 요약을 해보았다.  

- [Bayes Filter (Cyrill Stachniss)](https://youtu.be/0lKHFJpaZvE)  
- [SLAM DUNK Season 2 - Bayes Filter](https://youtu.be/y3U8vuUnTTc)  

Cyrill Stachniss의 강의 자료는 pdf로 [다운](https://drive.google.com/file/d/1l8JLsWDMMXLk3gxl1d9OWhzsxv2lGmDJ/view?usp=sharing) 받을 수 있다.  

## 2. Bayes Filter란?  

Bayes Filter를 이야기 하기 전에 우선 베이즈 정리(Bayes' theorem)가 무엇인지 간단히 알아보자.  

확률 시간에 들어볼 법한 <u>베이즈 정리는 이전의 경험과 현재의 증거를 토대로 어떤 사건의 확률을 추론하는 과정을 이야기한다. 이말을 조금 더 확률에 나온는 용어들을 활용해서 이야기하면 prior와 likelihood를 이용하여 posterior를 구할 수 있다는 의미</u>이다.  

자세한 내용은 아래의 블로그들을 참고하자.  

- [Bayes Rule (베이즈 룰)](https://hyeongminlee.github.io/post/bnn001_bayes_rule/)  
- [[확률과 통계] 14. 베이즈 정리, Bayes' Theorem / Bayes' Rule](https://blog.naver.com/mykepzzang/220834940797)  

Bayes Filter는 이러한 Bayes' theorem를 반복적으로 사용하는 Filter로 이해하면 된다.  

Cyrill 교수님은 강의 초반 Recursive State Estimation의 정의에 대해서 한번 언급해주신다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157166764-1e8e8da2-c9f7-4e19-b425-95327af4505c.png" width = "550" ></p>  

State Estimation이란 $t$라는 시간에서 로봇의 상태 $x$를 로봇의 관찰값(observation) $z$와, 로봇의 Control command $u$에 의해서 결정하게 되는 것이다.  

위 식은 1부터 $t$까지 주어진 observation $z$와 control command $u$를 고려해서 $t$번째 로봇의 상태 $x$를 추정하는 것이다.  

여기에 Recursive의 의미를 붙이면 로봇의 상태 $x_{t-1}$를 활용해서 로봇의 상태 $x_t$를 추정하는 것이다.  

Bayes Filter의 가장 유명한 에제인 Robot의 위치 찾는 것을 예를 들어 알아보자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157167915-cc787055-5ba2-4206-8c68-fbdfdb824752.png" width = "550" ></p>  

로봇은 1차원 공간을 가정하고, Door인지 아닌지 판단할 수 있다. 그리고 Global Environment에 대해 아무것도 모르는 상태라고 해보자. 처음은 아무것도 모르는 상태이기 때문에 로봇의 위치를 Uniform distribution으로 나타낼 수 있다.   

로봇의 움직이면서 문을 관찰했을 경우, $bel(x)$는 아래와 같이 변한다.  
(문을 관찰했으므로 문 앞에 로봇에 위치가 있을 확률이 높다고 판단하는 것이다.)  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157168301-ef3274fb-4ba2-4de9-87d7-e5d8b18bb586.png" width = "550" ></p>  

구한 $bel(x)$를 가지고 로봇을 앞으로 조금 움직여보자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157168534-aad1ac3d-66eb-4c9c-9b74-31a2170ea2fd.png" width = "550" ></p>  

우리가 예측했던 $bel(x)$의 모양은 그대로 이지만 로봇이 정확하게 얼마나 움직였는지 불확실성이 존재하기 때문에, 확률 분포가 조금 퍼져있는 형태로 나타내졌다.  

그리고 또 다시 한번 새로운 관찰값을 받아보자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157169040-12d232b2-d255-49d3-a8e5-4d713acbbe6f.png" width = "550" ></p>  

새로운 관찰값 $p(z|x)$ 와  
기존의 $bel(x)$의 확률 분포를 합쳐 새로운 $bel(x)$를 구할 수 있다.  


이처럼 로봇의 이전의 $bel(x)$ 값과  
observation 값($p(z|x)$)을 활용해서 현재의 $bel(x)$ 값을 나타내는 것이 Bayes Filter이다.  

## 3. Bayes Filter 식 유도  

먼저 식 유도를 하기 전 확률에 대한 기본적인 지식을 Remind해보자.  

1. Bayes' theorem  
2. Markov Property/Assumption  
3. Law of Total Probability  

Cyrill교수님은 강의 자료에서는 슬라이드로 정리를 해주셨다.  

- Bayes' theorem  

우리가 지금까지 봤던 베이즈 정리(Bayes' theorem)를 한 장의 슬라이드로 정리하면 아래와 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157170531-f414d564-1551-44a4-9d23-3279fba531e0.png" width = "500" ></p>  

---

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157170582-4660f66b-a1ff-4e2b-b49b-3cc5c512c6d2.png" width = "450" ></p>  

- Markov Property/Assumption  
  
그렇다면 Markov Property/Assumption이란 무엇일까?  

한마디로 이야기하면 <u>미래의 상태를 예측할 때, 현재의 상태에 대해서만 영향을 받고 그 이전 모든 과거의 상태에 대해서는 영향을 받지 않는다는 의미</u>이다. 즉, 미래는 과거와 독립적인 확률 과정을 가진다는 의미이다.   

- Law of Total Probability  

Law of Total Probability도 한 장의 슬라이드로 정리하면 아래와 같다.  

조건부 확률($p(x|y)$)로 부터 조건이 붙지 않은 전체 확률 ($p(x)$)를 구할 때 사용하는 법칙이다.  

Marginalization은 Law of Total Probability와 비슷한데 조건부 확률 대신 결합 확률을 사용했다는 차이점만 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157172197-5719444d-24fc-4afd-adde-85b6f08e7118.png" width = "600" ></p>  

Law of Total Probability에 대해 잘 설명해 놓은 [네이버 블로그([기초 통계] Law of Total Probability 란?)](https://m.blog.naver.com/sw4r/221385006874)도 있으니 참고해보면 좋을 것 같다.  

**그렇다면 자세하게 Bayes Filter를 수식적으로 파헤쳐보자.**  

우선 $t$번째 시간의 $bel(x_t)$를 정의하면 아래와 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157170056-8476c46f-ebd5-4608-b6e0-5506f58a01f2.png" width = "300" ></p>  

이를 Bayes' Rule을 적용하면 아래와 같이 바꿀 수 있다.  
$p(x,y) = p(y|x) p(x)$ 를 적용했다고 이해했다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157170215-fa93877a-103e-47c5-b4ed-dfc7ea34ec93.png" width = "500" ></p>  

위 식에서 첫번째 부분을 Markov Assumption을 적용하여 간략하게 나타낼 수 있다.  
$z_t$를 구하는데 그 이전 값들($z_{1:t-1} , u_{1:t}$)은 고려하지 않는다는 가정,  
$u_t$는 현재 값이지만 $z_t$를 구하는데는 영향을 끼치지 않는다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157171879-8835b0d6-7736-41a9-940e-3e75dadf230e.png" width = "500" ></p>  

Law of Total Probability를 활용해서 위 식의 두번째 Block의 식도 변형할 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157173893-150dfee7-dc93-4c5a-922d-9ffd4f0ce57e.png" width = "550" ></p>  

위 식에서 또 한번 Markov Assumption을 적용하여 식을 간단하게 나타낼 수 있다.  
$x_t$를 구하는데 그 이전 값들($z_{1:t-1} , u_{1:t-1}$)은 고려하지 않는다는 가정  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157174403-85d61e4b-4356-43ef-989c-e115a5b34de6.png" width = "600" ></p>  

위 식에서 맨 마지막 Block에 $p(x_{t-1})$을 구할 때 $u_t$는 고려하지 않아도 되므로 제거한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157174753-3c73eb41-3919-4e66-8e4a-d86997fdb5f7.png" width = "600" ></p>  

이전의 정의한 $bel(x_{t-1})$을 이용하여 식을 Recursive 형태로 써주면 아래와 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157174877-1b391d30-c385-4475-8027-e3d59d0e7dde.png" width = "600" ></p>  

## 4. Bayes Filter의 개념적인 접근  

Bayes Filter를 개념적으로 크게 두 가지로 분류할 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157178951-c7bcc4a7-b7a6-4c0d-86ae-f0213dfa6fa5.png" width = "600" ></p>  

- Prediction Step : 이전 값의 $bel(x_{t-1})$을 가지고 현재 control command인 $u_t$를 더하여 현재의 상태를 예측하는 단계이다.  

- Correction Step : Prediction Step에서 구한 값과 현재 관찰되는 값 ($z_t$)을 가지고 정교하게 상태 값을 계산한다.  

Prediction Step에서는 Motion Model을 이용하고, Correction Step에서는 Observation model을 이용한다.  

여기서 배운 Bayes Filter는 단지 State estimation을 할 때 사용하는 Framework으로 이해하면 된다.  

Motion model 및 Observation model을 어떻게 정의하느냐, 확률 분포를 어떻게 가정하느냐, Parametric filter인가 Non-parametric filter인가 에 따라 다양하게 확장이 가능하다.  

---

Bayes Filter에 대해서 정리를 하면 state estimation를 할 때 자주 쓰이는 Framework라고 이해를 하면 된다.  

여러 Filter들의 기본이 되는 Filter이므로 잘 알아두는 것이 중요하다.  

실제로 Bayes Filter를 사용할 때는 Motion model 및 Observation model을 어떻게 정의하느냐에 따라서 Bayes Filter를 구체적으로 설계할 수 있다.  

## 5. Reference  

- [[SLAM] Bayes filter(베이즈 필터)](http://jinyongjeong.github.io/2017/02/13/lec01_SLAM_bayes_filter/)  
- [베이즈 필터 (Bayes Filter)](https://gaussian37.github.io/autodrive-ose-bayes_filter/)  
