---
title : "Slam 3-1강 (Point Cloud Registration & ICP) 요약"
category :
    - Slam
tag :
    - Slam
toc : true
toc_sticky: true
comments: true
---

Cyrill 교수님의 SLAM 강의를 듣고 정리해보자!  

## 0. Today's Goal

- Point Cloud Registration이란?  
- Direct Optimal Solution with Known Data Association  
- Why solution used SVD is good?  

## 1. 강의 및 강의 자료  

강의 List는 [SLAM KR](https://www.youtube.com/channel/UCXvT7auo7xUd7v0B2pmvwIA)의 SLAM DUNK seson 2에서 정해준 강의를 따라 정리를 할 것이다.  

SLAM DUNK season 2의 Reference는 [여기](https://youtube.com/playlist?list=PLubUquiqNQdMYwQVftUSFEWhJgzBErO9N)서 확인해 볼 수 있다.  

SLAM KR에서 이 강의를 듣고 요약을 세미나 형식으로 준비를 해준다!

이번 포스팅은 다음의 강의들을 참고하여 요약을 해보았다.  

Point Cloud Registration & ICP의 경우 2021 강의에서 3번에 걸쳐 나눠 강의를 진행했기 때문에 그 강의를 듣고 요약을 진행했다.  

- [ICP & Point Cloud Registration - Part 1: Known Data Association & SVD (Cyrill Stachniss, 2021)](https://youtu.be/dhzLQfDBx2Q)    
- [SLAM DUNK Season 2 - Iterative Closest Points](https://youtu.be/BiQx5ISVdxU)  

Cyrill Stachniss의 강의 자료는 pdf로 [다운](https://drive.google.com/file/d/13NswuU_xD-OLTMOC3gLc2jpQvjXGS-HD/view?usp=sharing) 받을 수 있다.  

## 2. Point Cloud Registration이란?  

Point Cloud Registration이란 **두 Point Cloud를 정렬을 하는 공간 변환을 찾는 과정**을 말한다.  

이는 Mapping을 할 때 매우 중요한 과정인데 Scan matching을 하거나 Scan registration을 진행할 때 동일한 reference frame에서 보았을 때 각각의 Map point들이 일치해야 정확한 주위 환경을 Mapping 할 수 있기 때문이다.  

따라서 Point Cloud Registration을 통해 가장 정렬을 잘하는 Rotation Matrix $R$ 과 Translation Vector $t$를 찾는 것이 핵심이다.  

상황에 따라 해결법도 달라지는데,  
1. 두 Point Cloud의 대응관계(Correspondences)를 알 때 (Known Data Association)  
2. 두 Point Cloud의 대응관계(Correspondences)를 모를 때 (Unknown Data Association)  
3. Robust한 Least Squares Approaches를 이용하는 방법  

이번 강의에서는 **대응 관계를 알 때 SVD 알고리즘을 활용해 어떻게 Rotation Matrix $R$ 과 Translation Vector $t$를 찾는지 알아보자.**   

Known Data Association 일 때, 간단한 예로 Point Cloud Registration을 이해해보자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/134810803-95fbd31f-b420-41d4-999b-f1602401846d.png" width = "500" ></p>  

위 그림에서 빨간색 Point Cloud를 ${\{y_n\}}$, 파란색 Point Cloud를 ${\{x_n\}}$ 그리고 각각 Point들의 대응 관계를 $C$라고 하자.  

${\{y_n\}}, {\{x_n\}}, C $가 모두 주어졌을 때, Rotation Matrix $R$ 과 Translation Vector $t$를 활용하여 두 Point Cloud를 정렬할 수 있다.  

이 때, $R$과 $t$에 의해 옮겨진 Point Cloud를 $\{\bar{x_n}\}$ 이라고 하자.  

그럼 $\{\bar{x_n}\}$을 다음과 같은 식으로 표현할 수 있다.  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/134813581-b7ea6a73-2539-42a6-ac1c-c69bb3cdd11f.png" width = "200" ></p>  

이 때 <u>유클리디안 거리가 최소화 되도록 하는 $R$과 $t$를 찾는 것이 Point Cloud Registration</u>이다.  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/134813673-850d45b2-fa67-443d-9c2d-e297d61fc972.png" width = "300" ></p>  

## 3. Direct Optimal Solution with Known Data Association  

Point Cloud Registration을 풀기 전, 이 방법을 Absolute Orientation Problem의 특별한 경우라고 이야기했다.  

Absolute Orientation Problem이란 간단히 이야기하면 3D points의 집합을 정렬할 때 Transformation을 결정하는 문제이다. 이 또한 Cyrill 교수님의 [강의](https://youtu.be/sgLOU7vyz3g)로 설명을 들을 수 있다.(5분만에 정말 간단히 설명해주신다!)  

Absolute Orientation Problem에서는 Scale parameter도 존재하지만, 우리가 이번 강의에서 Point Cloud Registration을 할 때는 Scale parameter를 1로 고정하고 구하게 된다.  

따라서 Point Cloud Registration을 Absolute Orientation Problem의 특별한 경우라고 하는 것이다.  

다시 Point Cloud Registration을 푸는 방법을 이야기해보자.  

우리가 대응관계(Correspondences)를 알고 있을 때는 **Initial guess가 없어도, Iterate를 돌지 않아도 완벽한 해(Solution)를 구할 수 있다는 것이다!**  

이를 구하는 방법은  
1. Translation 값을 구하기 위해서 두 Point Cloud의 Center of massess(질량 중심)을 일치시키고, 이동량을 계산한다.  

2. Rotation 값을 구하기 위해서 SVD(Singular Value Decomposition)을 수행한다.  

식으로 이를 표현해보자.  

먼저 ${\{x_n\}}$의 Weighted mean을 ${\{x_0\}}$, ${\{y_n\}}$의 Weighted mean을 ${\{y_0\}}$이라고 하자.  

아래 식에서 $p_n$은 가중치(Weight)를 의미한다.   

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135045532-26e3364e-807c-49f6-bba5-87555ccac9e2.png" width = "200" ></p>  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135045679-ddcd4393-5bd4-47a4-bfad-3f7b007bd365.png" width = "200" ></p>  

위에서 구한 값들을 활용하여 교차 공분산 행렬(Cross Covariance Matrix) $H$를 계산한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135046070-1ff4ff31-cf39-4d66-aac2-a1f26ae35207.png" width = "300" ></p>  

그리고 $H$에 대해 SVD를 계산한다.  

SVD를 이용하여 Rotation Matrix $R$을 구하는 식은 다음과 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135046847-0655eb2d-6c04-438b-8734-611d524331fb.png" width = "200" ></p>  

그리고 현재까지 구한 값들을 활용하여 Translation Vector $t$를 구하는 식은 다음과 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135047135-1f7e04ab-b3cc-4995-ae64-f1f175fd41c6.png" width = "400" ></p>  

Rotation Matrix $R$와 Translation Vector $t$를 구하므로써 우리가 원하는 Point Cloud Registration을 풀었다!  

위 과정을 한 장의 슬라이드로 정리하면 다음과 같다.  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135047617-f9fa9c6d-0fd5-42f9-8945-46971eb25763.png" width = "500" ></p>  


## 4. Why solution used SVD is good?

그렇다면 왜 이 방법이 최적의 해(solution)일까?  
우리는 왜 초기값(Initial guess)이 필요하지 않으며 Iterate를 돌지 않아도 완벽한 해를 구할 수 있는 것일까?  

이유를 알기 위해서 우리가 구하는 식을 재정의(Rewrite) 해보자.  

우리가 원래 구해야 하는 식은 다음과 같다.  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/136338388-39ab1c05-12de-414b-936f-eaef841e0fbb.png" width = "300" ></p>  

이 식을 원점(origin)이 $y_0$인 Local Coordinate System으로 다시 재정의해보자.  

이전에 정의한 것과 같이 $y_0$을 아래와 같이 정의 한 후,  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/135045679-ddcd4393-5bd4-47a4-bfad-3f7b007bd365.png" width = "200" ></p>  

우리가 구해야 하는 식을 아래와 같이 변경하자.  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/136338934-198e3b3a-f8f5-4859-8131-f95a2a7d15b0.png" width = "500" ></p>  

이렇게 되면 구해야하는 Translation Vector가 바뀌였다.  

다시 Translation Vector를 재정의 해보자.  

$\bar{x_n} = Rx_n + t$ 식을 원점($y_0$)을 활용하여 이동시키면,  
$\bar{x_n} - y_0 = Rx_n + t - y_0$ 으로 쓸 수 있다.  

Rotation Matrix로 우변을 모두 묶으면 아래와 같은 식이 나온다.  
$\bar{x_n} - y_0 = R(x_n + R^T t - R^T y_0)$  

여기서 $R^T$는 Rotation Matrix의 전치행렬이다.  

새로운 변수 $x_0$을 활용하여 다시 식을 정의해보자.  
아까 Weighted mean을 구할 때 쓰던 변수가 아니다!  

$x_0 = R^T t - R^T y_0$ 이라고 할 때  

우리가 구해야 하는 식을 다음과 같이 쓸 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/136341639-b35e6f57-b4b8-4673-b812-563e6d9e89c0.png" width = "500" ></p>  

그렇다면 우리가 찾아야 하는 변수는 $R,t$가 아니라 $R, x_0$를 찾는 문제로 바뀐다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/136341927-4db055f7-e781-4faa-a589-a596f9b1aaed.png" width = "500" ></p>  

우리가 구해야 하는 식은 2차식인데 이를 행렬로 표현하여 Objective function을 정의한다.  

Objective function은 최적화시키려는 함수를 의미한다.  

Objective function $\Phi(x_0,R)$이라 정의하고, 이를 최소화시키는 $x^*_0, R^*$ 을 구하면 우리가 원하는 해를 구할 수 있다.  

$\Phi(x_0,R)$는 아래와 같이 정의한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/136343093-7df8ffe0-9619-4197-b815-1af65149156e.png" width = "500" ></p> 














