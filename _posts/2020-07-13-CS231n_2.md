---
title : "CS231n 2강 요약"
category :
    - machine_learning
tag :
    - machine_learning
    - computer vision
toc : true
comments: true
---

드디어 본격적으로 강의를 배우는 첫번째 시간이다.

차근차근 한번 배워보자!

## 0. Today's Goal
> - Image Classification 이란?
> - Classification Algorithm에 대해서 알아보자.
> - Hyperparameters란?
> - Linear Classification의 간략한 개념설명

## 1. 강의 및 강의 자료

1강과 마찬가지로 강의는 유튜브에 올라와 있고, 강의 자료도 홈페이지에 나와있다.

친절하게 한글 자막까지 만드신 분도 있다..

- 강의 링크 : [video](https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=2)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/4908861/cs231n_2017_lecture2.pdf)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. 강의 요약

### Image Classification에 대해서

먼저 Image Classification에 대해서 배운다.

**Image Classification** 이란 입력 이미지가 들어왔을 때,  
이미 정해져 있는 <U>Categories에서 이미지가 어떤 Category에   
속할지 고르는 문제</U>이다.

그렇다면 Computer 입장에서 Image Classification이 어려운 이유는 무엇일까?

사람은 입력 이미지를 이렇게 보지만,
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87251959-7edb3100-c4aa-11ea-90c8-76a1df0f8a36.png" width = "200" ></p>

컴퓨터는 이렇게 보기 때문이다. (단지 숫자들의 집합..)
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87251961-839fe500-c4aa-11ea-8890-803e0910d704.png" width = "250" ></p>

따라서 다음과 같은 변화에 이미지를 분류하기 굉장히 어렵다.

1. Viewpoint variation (카메라의 위치 변화)
2. Illumination (조명에 의한 변화)
3. Deformation (객체 변형에 의한 변화)
4. Occlusion (객체 가려짐에 의한 변화)
5. Background Clutter (배경과 유사한 색의 객체)
6. IntraClass variation (클래스 내부의 분산)

---

만약 Image Classification Algorithm을 작성할 때,  
접근 방법은 2가지이다.

> 1. Image의 Feature(특징)을 찾고 Feature(특징)을 이용하여 명시적인 규칙을 만드는 방법으로 접근
> 2. 데이터를 보고 데이터 중심으로 접근 

- 이미지의 특징으로 명시적인 규칙을 만드는 방법으로 접근한 경우
    문제점이 존재하는데, 
    1. Algorithm이 Robust(강인)하지 않다.
    2. 확장성이 없다. >> 다른 이미지에 적용이 어렵다.  


- 데이터를 보고 데이터 중심으로 접근한 경우
    수많은 데이터를 수집해야 한다는 문제점이 있지만,
    최근 하드웨어의 발전으로 성능이 좋아졌다.

데이터 중심 접근 방법에서 분류 알고리즘(Machine Learning)을 사용하는데, 
그 중 하나인 Nearest Neighbor Algorithm을 살펴보자.

---
### K-Nearest Neighbor Algorithm에 대해서

K-Nearest Neighbor Algorithm은 분류 알고리즘으로써, 새로운 데이터가 들어왔을 때 어떻게 분류를 할 것인가?
정해주는 알고리즘이다.

K-Nearest Neighbor는 크게 두가지 과정을 거치는데

1. Train 과정 : 모든 train data를 기억한다.

2. Predict 과정 : 입력 데이터를 train data와 비교하며 어떤 label 값을 가질지 예측한다.

K-Nearest Neighbor Algorithm에 영향을 미치는 parameters는 크게 두가지가 있다.
> 1. K값
> 2. Distance Metric(거리 척도)

먼저 K값에 의해 Overfitting(과적합)이 일어나는 것을 막아준다.

예를 들어, K = 1일 때 다음과 같이 영역을 분류했다면
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87252412-c616f100-c4ad-11ea-9c55-44fdd54346c1.png" width = "250" ></p>

K값을 조절함으로써, 경계선을 좀더 부드럽게 만들어주거나 영역을 좀 더 잘 분류한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87252444-0d04e680-c4ae-11ea-8f02-85f4be1df793.png" width = "450" ></p>

Distance Metric(거리 척도)에 따라서는 경계선에서 약간의 차이를 볼 수가 있다.

보통 L1 distance, L2 distance를 사용하는데
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87252575-340fe800-c4af-11ea-8d63-22c59eb051cd.png" width = "500" ></p>

특정 벡터가 개별적인 의미를 가지고 있다면 L1 distance를,
일반적인 벡터 요소들의 의미를 모르거나 의미가 별로 없을 때는 L2 distance를 사용한다.

좌표계에 따라서도 Distance Metric이 어떤 것인지에 따라 결과 값이 달라진다.

앞선 예로 결과의 차이를 확인하면,
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87252626-8a7d2680-c4af-11ea-933c-5e7e25548126.png" width = "500" ></p>

여기서 K값, Distance Metric(거리 척도)와 같은 Parameter들을
**HyperParameter**이라고 한다.

즉, <U> **HyperParameter**는 학습을 하는데 영향을 미치는 parameter</U>이고 <U>학습을 하기 전 선택하는 parameter</U>이다.

HyperParameter를 어떻게 하면 잘 선택할 수 있을까?

다양한 방법들이 있지만, Dataset이 있을 때 train, val, test로 나누어
한번도 보지못한 data에 대해 분류를 잘 하게 되는 Hyperparameter를 선정한다.

