---
title : "CS231n 3강 요약"
category :
    - CS231n
tag :
    - machine_learning
    - computer vision
    - CS231n
toc : true
comments: true
---

오늘은 loss functions와 optimization에 대해 배워보자!

## 0. Today's Goal
> - Loss function에 대해서 알아보자.
> - Regularization이란?
> - Softmax vs SVM
> - Optimization에 대해서 알아보자.

## 1. 강의 및 강의 자료

강의를 들어볼 수 있는 링크와 강의 자료를 pdf형식으로 준비했다.

- 강의 링크 : [video](https://www.youtube.com/watch?v=h7iBpEHGVNc&t=2096s)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/4910668/cs231n_2017_lecture3.pdf)

한글 자막이 필요하신 분은 다음의 링크를 확인해주세요. :)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. 강의 요약

### Loss function에 대해서

Loss function을 번역하면 '손실 함수'이다. 앞선 강의에서 weight에 대한 개념을 잡았다. 손실함수는 <U>weight를 입력으로 받아서 weight의 결과가 정답 값과 얼마나 차이가 나는지 보여주는 역할</U>을 한다.

손실 함수에도 여러가지 종류가 있는데 우선 우리가 알아볼 손실 함수는
**Multiclass SVM loss**이다.

**Multiclass SVM loss**는 각 클래스에 대한 점수를 매겼을 때,
**그 점수(score)가 정답과 얼마나 차이가 나는지만 관심이 있는 함수**이다.


예시를 통해 알아보면 만약 분류해야 할 클래스가 3개이고  
$f(x,W) = Wx$라는 함수를 사용해서 클래스에 대해 점수를 매긴다고 하자.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87272775-3b1c1200-c512-11ea-8d41-2dada5c5d8de.png" width = "400" ></p>

각 항에 숫자가 의미하는 것은 분류기를 통해 예측한 클래스별 점수이다.
이 분류기(function)의 경우 자동차에 대해서는 잘 분류를 하지만, 다른 그림에 대해서는 분류를 잘 하지 못하는 것이라고 볼 수 있다.

그렇다면 <U>이 분류기가 얼마나 분류를 잘하는지 알아보기 위해
Loss function을 이용하여 수치화</U>를 한다.

우리는 얼마나 분류기가 잘 분류하는 건지 알아보고 싶은건데,
공식을 이용하여 수식으로 표현하면

$$ L = \frac  1 N \sum_i L_i(f(x_i,W),y_i) $$

- $L_i$는 사용할 loss function
- $f(x_i,W)$는 내가 분류기를 사용해서 나온 클래스의 점수
    저 그림에서는 3.2, 5.1, -1.7 같은 숫자들..
- $y_i$는 실제 클래스의 정답 값
- $N$은 클래스의 수 (여기서는 3이 된다.)

어떤 $L_i$를 쓰는 것인가에 따라 또 $L$의 값이 달라진다.

우리는 처음에 Loss function을 **Multiclass SVM loss**로 설계했으므로
이에 대해 Loss function을 다음과 같이 식으로 표현할 수 있다.

$$ L_i =  \sum_{j \neq y_i} max(0,s_j - s_{y_i} + 1)   $$

- $s_j$는 분류기를 통해 예측한 점수(score)
- $s_{y_i}$는 그 클래스의 정답 점수(score)
- 1은 'safty margin', 예측 값과 정답 값에 대한 상대적인 차이를 주기 위해 설정

**Multiclass SVM loss**를 그래프로 그려보면

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274369-951ed680-c516-11ea-8b0d-73950b02eea7.png" width = "400" ></p>

정답 클래스를 가장 높은 점수를 매긴다면 $L_i$의 값은 0에 가까울 것이고,
그렇지 않다면 Loss의 값이 크게 오를 것이다.

앞선 예시에서 Loss의 값을 계산한다면,

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274536-edee6f00-c516-11ea-9da1-6f1701491589.png" width = "150" ></p>

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/87274812-9ef50980-c517-11ea-88b3-a80a1a88f3c3.png" width = "300" ></p>

이런 식으로 계산을 할 수 있다. 
차례대로 car 클래스와 frog 클래스에 대해서도 Loss를 계산할 수 있다.

여기서 **Multiclass SVM loss**에 대해 몇가지 질문을 던지는데..

> - Q1 : car score이 변하게 된다면 loss의 값은 어떻게 되는가?
> - Q2 : loss값의 최솟값과 최댓값을 구하면?
> - Q3 : 초기에 W가 0에 가까우면 모든 score의 값은 0과 비슷하다. 
    이때 loss값을 구하면?
> - Q4 : $L_i$값을 구하는데 합을 구할 때 ${j \neq y_i}$가 아닌, $j$를 포함한 모든 값을 다 더하게 되면?
> - Q5 : Loss를 계산하는데, 합 대신 평균을 사용하면 Loss값은 어떻게 되는가?
> - Q6 : 손실 함수를 $max(0,s_j - s_{y_i} + 1)$가 아닌 $max(0,s_j - s_{y_i} + 1)^2$을 사용하게 된다면?

모두 다 심오한 질문들이다...

친절하게 모든 문제에 답을 해준다.

> - A1 : score 간에 상대적인 차이가 중요하므로 loss의 값에는 크게 영향을 미치지 않는다.
> - A2 :  그래프를 생각해본다면 최솟값은 0 , 최댓값은  $\infty$ 이다.
> - A3 : Loss는 '(클래스) - 1'이 된다. 이는 디버깅할 때 유용한 팁이 된다.
> - A4 : 






