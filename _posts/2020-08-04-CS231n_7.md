---
title : "CS231n 7강 요약"
category :
    - CS231n
tag :
    - machine_learning
    - computer vision
    - CS231n
toc : true
comments: true
---


Neural Network를 Training 시킬 때, 고려해야 하는 것들을 추가적으로 알아보자!

## 0. Today's Goal
> - Optimization의 여러가지 기법들
> - Regularization
> - Transfer Learning 


## 1. 강의 및 강의 자료

강의를 들어볼 수 있는 링크와 강의 자료를 pdf형식으로 준비했다.

- 강의 링크 : [video](https://www.youtube.com/watch?v=_JB0AO7QxSA&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=7)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/5017482/cs231n_2017_lecture7.pdf)

한글 자막이 필요하신 분은 다음의 링크를 확인해주세요. :)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. Optimization의 여러가지 기법들

### 다양한 Optimization Algorithm 소개

지금까지 배운 최적화 기법은 SGD Algorithm이 있다.
간단하게 SGD Algorithm에 대해 설명해보면,
> 1. Mini batch 안에 있는 data의 loss를 계산
> 2. Gradient의 반대 방향을 이용하여 update를 한다.
> 3. 1번과 2번 과정을 계속해서 반복한다.

하지만 SGD Algorithm에는 문제점이 존재하는데,

- **Loss의 방향이 한 방향으로만 빠르게 바뀌고 반대 방향으로는 느리게 바뀐다면 어떻게 될 것인가?**  
<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91394228-674ae280-e875-11ea-9ac7-746f470d4cc6.png" width = "500" ></p>

> 이렇게 불균형한 방향이 존재한다면 SGD는 잘 동작하지 않는다.

- **Local minima나 saddle point의 빠지면 어떻게 될 것인가?**

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91407190-7b92dd80-e87d-11ea-8b85-3f9bf9021f4a.png" width = "500" ></p>

> 최솟값이 더 있는데 local minima에 빠져서 나오지 못하거나,  
> 기울기가 완만한 구간에서 update가 잘 이루어지지 않을 수 있다.  

- **Minibatches에서 gradient의 값이 노이즈 값에 의해 많이 변할 수 있다.**

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91408042-27d4c400-e87e-11ea-9dd8-dfd3c7bee6bd.png" width = "500" ></p>

> 그림처럼 꼬불꼬불한 형태로 gradient 값이 update 될 수 있다.

---

위와 같은 문제점들을 해결하기 위해서 **Momentum**이라는 개념을 도입한다.



**Momentum**이란 자기가 가고자 하는 방향의 속도를 유지하면서 gradient update를 진행하는 것을 말한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91408257-8a2dc480-e87e-11ea-9b1c-c7903030b313.png" width = "600" ></p>

momentum을 추가하는데 기존에 있는 momentum과는 다르게 순서를 바꾸어 update를 시켜주는 방법도 있는데 **Nesterov Momentum**이라고 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91409022-c4e42c80-e87f-11ea-9a6f-b2bacae9d551.png" width = "500" ></p>

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91409164-feb53300-e87f-11ea-8c23-2ef98d512be7.png" width = "500" ></p>

식의 의미를 잘 이해하진 못했지만, 강의에서는 현재 / 이전의 velocity 간의 에러 보정이 추가되었다고 설명했다..

기존의 SGD, SGD+Momentum, Nesterov의 결과값을 한 번 비교해보면,

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91409306-3623df80-e880-11ea-8ebd-2c28940eb2d4.png" width = "500" ></p>

좀 더 Robust하게 algorithm이 작동하는 것을 볼 수 있다.

---

velocity term 대신에 grad squared term을 이용하여 gradient를 update하는 방법도 제안되었는데,  
이 방법은 **AdaGrad**라고 부른다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91410081-4daf9800-e881-11ea-9c2d-72e5f80f0d55.png" width = "500" ></p>

이러한 방식으로 update를 계속 진행하게 되면,  
small dimension에서는 가속도가 늘어나고,  
large dimension에서는 가속도가 줄어드는 것을 볼 수 있다.  

그리고 시간이 지나면 지날수록 step size는 점점 더 줄어든다.  

이 방법에서 또 하나가 추가가 되어 decay_rate라는 변수를 통해서  
step의 속도 가 / 감속을 할 수 있는 방법이 제안되었는데,  
이 방법을 **RMSProp**이라고 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91410355-c1ea3b80-e881-11ea-99e1-837db69a6d89.png" width = "500" ></p>

정말 수많은 알고리즘들이 제안되었는데,  
이제 대중적으로 널리 쓰이고 있는 **Adam**에 대해서 알아보자.

**Adam**은 쉽게 생각하면 momentum + adaGrad 라고 생각하면 된다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91410603-1b526a80-e882-11ea-873d-375a79b5d9e5.png" width = "500" ></p>

초기화를 잘 해주어야 하기 때문에, bias correction을 추가하여  
초기화가 잘 되도록 설계해 주었다.

앞선 알고리즘과 한번 비교를 해보면,  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91411263-0c1fec80-e883-11ea-9a75-63c1c6af4943.png" width = "500" ></p>

음.. Adam이 제일 대중적으로 쓰인다고 했는데 여기 보여준 예제에서는 좀 멀~리 돌아서 update가 된 것 같긴하다.

지금까지 보여준 최적화 알고리즘은 모두 **Learning rate**를 hyperparameter로 가지고 있다.

Learning rate decay도 있지만, 처음에는 없다고 생각하고 딥러닝 모델을 설계한 다음, 나중에 고려해주도록 하자.

---

### First-Order & Second-Order Optimization

일차 함수로 근사화를 시켜 최적화를 시킬 때는 멀리 갈 수 없다는 단점이 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91411812-d9c2bf00-e883-11ea-9912-47cfa470186e.png" width = "500" ></p>

이차 함수로 근사화를 시킬때는 주로 테일러 급수를 이용해서 근사화를 시킨다.  
이러한 방법으로 update를 시키면 기본적으로 learning rate를 설정해 주지 않아도 된다는 장점이 있다. (No Hyperparameters!)  
하지만 복잡도가 너무 크다는 단점이 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91412125-4a69db80-e884-11ea-910c-985c410a1365.png" width = "500" ></p>

Quasi-Newton 방법으로 non-linear한 최적화 방법 중에 하나이다.  
newton methods보다 계산량이 적어 많이 쓰이고 있는 방법이다.  
그 중 가장 많이 쓰는 알고리즘은 **BGFS와 L-BGFS**이다.

이러한 알고리즘들은 full-batch일 때는 좋은 성능을 보이기 때문에, stochastic(확률론적) setting이 적을 경우 사용해 볼 수 있다.

지금까지 배운 방법들은 모두 Training 과정에서 error를 줄이기 위해 사용하는 방법들이다.  
그렇다면 한 번도 보지 못한 데이터에서 성능을 올리기 위해서는 어떻게 해야할까?

## 3. Regularization

Regularization 기법을 설명하기 전에, **Model Ensembles**에 대해서 한 번 정리하자.

**Model Ensembles**은 간단히 말하면 다양한 모델로 train을 시키고, test를 할 때 그 것들을 짬뽕(?)해서 쓰는 것을 말한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91413966-d41aa880-e886-11ea-97de-fcc3cf6c0827.png" width = "600" ></p>

Test를 할 때, parameter vector들을 Moving average값을 사용하여 test를 하는 방법도 있다. (Polyak averaging)  

지금까지의 방법들은 모두 Test를 하는데 좋은 성능을 내기 위해 모델을 좀 더 robust하게 만들기 위해서 사용하는 기법들이다.  

그렇다면 single-model의 성능을 좋게 하기위해선 어떤 방법을 쓸까?

답은 **Regularization**이다.

**Regularization**은 간단히 loss function을 구현할 때, regularization에 대한 function을 추가해주기도 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91414546-af730080-e887-11ea-8cf8-677c137eb58b.png
" width = "500" ></p>

또 다른 방법으로는 dropout이라는 기법도 있다.
Dropout이 효과가 있는 이유는 다양한 feature를 이용하여 예측을 하기 때문에 어떤 특정 feature에만 의존하는 경우를 방지한다.  
또한 단일 모델로 앙상블 효과가 날 수 있도록 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91415253-b9e1ca00-e888-11ea-9781-03722c6a9851.png
" width = "500" ></p>


test-time에서 임의성에 대해 평균을 내고 싶을 때..

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91415500-193fda00-e889-11ea-9ebd-54666d3d254a.png
" width = "500" ></p>

dropout을 하게 되면 test time도 줄어들게 할 수 있다.

또다른 regularization 방법으로는 **Data Augmentation**이 있다.  

training을 시킬 때, 이미지의 patch를 random하게 잡아서 훈련을 시키거나, 

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91416245-1396c400-e88a-11ea-8db4-7368b3ff0d6f.png
" width = "500" ></p>

이미지를 뒤집어서 train dataset에 추가해 훈련을 해주거나,  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91416391-48a31680-e88a-11ea-91b0-6dbf05c8d1b5.png 
" width = "500" ></p>

밝기값을 다르게 해서 train dataset에 추가하고 훈련을 해주는 경우도 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91416541-7d16d280-e88a-11ea-894e-6d52a3392e98.png 
" width = "500" ></p>

이 외에도 다양한 regularization 방법들이 존재한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91416702-be0ee700-e88a-11ea-8a31-8b5fea4f5e20.png 
" width = "500" ></p>

## 4. Transfer Learning 

전이학습은 간단히 말하면 이미 pretrained된 모델을 이용하여 우리가 이용하는 목적에 맞게 fine tuning하는 방법을 말한다.

Small Dataset으로 다시 training 시키는 경우 보통의 learning rate보다 낮춰서 다시 training을 시킨다.

DataSet이 조금 클 경우, 좀 더 많은 layer들을 train 시킨다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91417070-35dd1180-e88b-11ea-8fdb-aa5a86bc9faa.png 
" width = "600" ></p>

한 번 더 표로 정리해보면,

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91417167-586f2a80-e88b-11ea-8c77-1037c7d4174a.png 
" width = "600" ></p>

전이학습은 많이 사용하는 방법이니 꼭 알아두자!

---

다음 시간에는 Deep Learning Software에 대해서 배운다. 어떤 프레임워크가 있는지 한 번 알아보자.