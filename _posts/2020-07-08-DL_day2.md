---
title : "딥러닝 바로 써먹기 Day 2"
category :
    - machine_learning
tag :
    - machine_learning
    - keras
toc : true
comments: true
---

**데이터 분석과 이미지처리에 딥러닝 바로 써먹기** 두번째 시간이다.

오늘은 레이어의 개념을 잡는 시간을 가졌다.

## 0. Today's Goal
> - 데이터셋 준비 방법 알아보기
> - 컨볼르션 신경망 레이어 이해하기
> - 한 층(Layer)에서 입력과 출력이 정해졌을 때, Weight의 수 구하기
> - 출력의 채널 수 및 크기 구하기
> - 딥러닝 용어 정리하기
> - 목표함수(objective function)는 어떻게 정해야 하는것일까?

## 1. 데이터셋 준비

수많은 데이터셋을 준비했다면, 이제 데이터셋을 분류해야 한다.

학생들이 시험을 볼 때 미리 시험문제를 알고 푼다면, 의미가 없듯이

딥러닝 모델을 평가할 때도 새로운 데이터셋을 가지고 평가를 해야한다.

데이터셋은 3가지로 나누어야 하는데,

**훈련셋, 검증셋, 시험셋** 으로 나누어야 한다.

여기서는 학생들이 수능을 보는 것으로 예시를 들었다.


<p align="center"><img src="https://user-images.githubusercontent.com/41863759/86865227-8ea0f100-c109-11ea-979c-f5c679434772.png"></p>


**훈련셋**은 말그대로 훈련하는데 쓰이는 데이터셋이다. 이 데이터셋을 가지고 네트워크의 웨이트(weight) 값들을 갱신하게 된다.

**검증셋**은 훈련이 제대로 되었나 안되었나, 자기 스스로 평가를 할 수 있도록 만든 데이터셋이다. 검증셋이 있어야 학습 방법을 변경하거나, 최적의 학습 방법을 찾을 수 있게 된다. 검증셋은 네트워크의 웨이트 값들에는 영향을 미치지 않는다.

**학습 방법을 결정하는 파라미터를 <U>하이퍼파라미터(hyperparameter)</U> 라고 한다.**
**최적의 학습 방법을 찾는 과정을 <U>하이퍼파라미터 튜닝</U>이라고 한다.**

**시험셋**은 검증의 과정을 거친 여러가지 네트워크들을 실제 데이터를 적용하기 전 평가하는 데이터셋을 말합니다.

검증셋은 학습을 하는 과정에 체크를 하는 것이고, 시험셋은 학습이 다 완료된 후 체크를 하는 것입니다.

## 2. 컨볼르션 신경망 알아보기

영상처리에서 쓰이는 이미지는 주로 2D(2차원)이기 때문에 딥러닝 모델을 설계할 때, Conv2D layer를 사용합니다.

keras에서는 다음과 같이 사용합니다.
```py
Conv2D(32, (5, 5), padding='valid', input_shape=(28, 28, 1), activation='relu')
```

- 첫번째 인자 : 필터의 수를 의미합니다.
- 두번째 인자 : 필터의 크기를 의미합니다.
- padding : 가장자리 처리를 어떻게 할 것인지 정합니다.
    주로 'valid'나 'same' padding을 많이 사용합니다.  
    valid padding : 유효한 값을 가진 영역만 출력을 합니다.  
    same padding : 출력 이미지의 사이즈를 입력 이미지의 사이즈와 동일하게 합니다.
- input_shpae = (가로,세로,채널)을 의미합니다.
- activation = 활성화 함수를 정합니다.
    주로 softmax, sigmoid, relu등을 사용합니다.

필터는 가중치를 의미합니다.

예를 들어 한번 Conv2D에 대해 살펴봅시다.

input_shpae가 (3,3,1)인 이미지가 들어오고, 필터의 크기는 (2,2),
필터의 수는 1개라고 했을 때 이를 레고 블럭으로 도식화하면

![image](https://user-images.githubusercontent.com/41863759/86867613-17ba2700-c10e-11ea-8b8e-b9280b9ad7fd.png)

여기서 쓰인 가중치의 수는 몇개 일까요?

초록색 블럭의 갯수가 가중치의 수 이므로 총 4개입니다.

하나의 필터가 입력 이미지를 순회하면서 적용된 결과값을 모으면 출력 이미지가 생성됩니다.

여기에는 2가지 특성이 존재합니다.
> - 하나의 필터로 이미지를 순회하기 때문에 가중치의 수가 적다. 이를 <U>파라미터 공유</U>하라고 합니다.
> - 출력의 영향을 미치는 입력의 데이터가 한정되어 있습니다. 이는 지역적인 특징을 잘 뽑아내서 영상 인식을 하는데 적합합니다.

이를 Dense Layer와 비교를 한번 해보겠습니다.

현재 예시에서 입력은 (3,3) , 출력은 (2,2) 이므로 총 9개의 데이터를 Input으로 넣고, 출력 데이터는 4로 나타낼 수 있습니다.

Dense Layer에서 가중치의 수는 입력의 데이터 수 * 출력의 데이터 수 이므로 총 가중치의 수는 36개입니다.

Conv2D layer를 사용하면 Dense layer를 사용할 때보다 훨씬 적은 가중치로 결과를 뽑아낼 수 있다는 것을 알 수 있습니다.

Conv2D layer에서 가중치의 수, 출력 필터의 수를 공식으로 적어보면 다음과 같습니다.

- **가중치의 수 = (필터의 가로 * 필터의 세로) * 갯수**

단, 여기서 <U>갯수</U>라는 말에 유의를 해야하는데, 필터의 수가 갯수가 될 수 있고, 입력 이미지의 채널의 수가 갯수가 될 수 있습니다.

**입력 이미지의 채널의 수와 필터의 수를 비교하여
더 큰 값이 갯수**로 정해집니다. (말이 좀 어렵네요..) 

또한 출력 필터의 수는

- **출력 이미지의 수 = 필터의 갯수**

로 공식화(?) 할 수 있습니다.

입력 채널이 1개인데, 필터의 수가 3개면? 당연히 출력 이미지의 수는 3개입니다. 카메라의 여러 필터를 사용하여 사진을 찍는 것이라고 생각하면 이해하기 수월합니다.

다양한 예시를 들어 설명한 블로그를 참고에 첨부해 놓도록 하겠습니다.

## 3. 딥러닝 용어 정리하기

역시 처음 공부를 하다보면 가장 헷갈리는 것이 단어입니다.

저도 공부를 하는 입장에서 제가 이해한 만큼 단어 정리를 해보도록 하겠습니다.

- **Batch size란?**
> 딥러닝 모델을 학습을 시킬 때, 몇 개의 샘플로 학습을 해서 Weight의 값을 갱신할 것인지 정하는 것을 말한다.
> 예를 들어 학습해야할 데이터의 수가 100개 일때, batch size가 10이면 weight는 10번 갱신되고 batch size가 20이면 weight는 5번 갱신된다.

- **Epoch란?**
> 준비된 데이터를 몇번 반복할지 정하는 횟수를 말한다. 준비된 데이터를 모두 학습을 하였다면 epoch가 1인 경우이다.

- **Pooling이란?**
> 입력 데이터를 축소하는 과정을 말한다. Sampliing이라고 생각하면 이해하기 쉬울 것 같다. average pooling과 max pooling이 많이 쓰이는 pooling 방법이다.

- **Padding이란?**
> 출력 이미지의 가로와 세로의 크기를 정하는데 결정적인 역할을 한다. 
가장 자리의 값을 0으로 정하고 싶으면 valid padding, 가장 자리의 값을 인접한 데이터의 값과 같다고 정하고 싶으면 same padding으로 정하면 된다.
**입력 이미지의 edge쪽 픽셀 정보를 이용하기 위해 padding이라는 작업을 거친다.**

- **One-hot 인코딩이란?**
> 단 하나의 값만 True이고, 나머지 값들은 모두 False로 만드는 인코딩을 말한다.
> 데이터를 쉽게 중복없이 표현할 때 사용한다.

## 4. 목표함수(objective function) 정하기

딥러닝 모델을 구성할 때 네트워크, 목표함수, 최적화기로 구성되어 있다고 배웠다. 

네트워크도 여러가지 종류가 있고 목표함수도 여러가지 종류가 있는데,
목표함수는 어떻게 정해지는지 한번 알아보자.

자주 쓰이는 함수는 MSE(Mean Squared Error), binary_crossentropy,categorical_crossentropy 등이 존재한다.

Mean squared error 같은 경우 수치를 예측할 때 사용하고,
binary_crossentropy의 경우 이진 분류를 할 때 사용한다.
마지막으로 categorical_crossentropy의 경우 다중 분류를 할 때 사용한다.

binary_crossentropy와 categorical_crossentropy의 차이점을 알아보자.
다른 부분은 대부분은 비숫하지만, 결정적으로 
**output layer에서 activation function을 softmax를 쓰면 categorical_crossentropy이고 sigmoid를 쓰면 binary_crossentropy이다.**

---
sigmoid 함수는 0.0 ~ 1.0 사이의 실수를 가지는데, 이 특성을 이용해서 0.5보다 크면 양성 적으면 음성으로 나눈다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/86877686-4e9a3800-c122-11ea-96d0-9606291c1dc8.png" width = "300" ></p>

---

softmax 함수는 벡터의 수를 분류할 클래스 수만큼 가지고 각 벡터는 0.0과 1.0사이의 수가 나온다. 또한 그 합들은 1.0이 되어야 한다는 특징이 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/86877895-c36d7200-c122-11ea-8962-92680b78defc.png" width = "400" ></p>

## 5. 정리

- 데이터셋은 학습셋, 검증셋, 시험셋으로 나누고 사용한다.
- 이미지 딥러닝 모델에서는 Conv2D layer를 주로 사용한다.
- Conv2D의 가중치의 수는 가중치의 수 = (필터의 가로 * 필터의 세로) * 갯수
- 출력 이미지의 필터의 수 = Conv2D 필터의 갯수
- 출력 이미지의 가로와 세로는 필터 크기와 padding option에 의해 결정된다.

## 6. 참고자료

- 케라스 코리아 김태영 대표님 블로그 : <https://tykimos.github.io/index.html>
- Sungkim softmax에 대한 설명 :<https://www.youtube.com/watch?v=lvNdl7yg4Pg>
- binary_crossentropy와 categorical_crossentropy 차이 : <https://utto.tistory.com/8>
- keras 실습 예제 : <https://keras.io/examples/vision/image_classification_from_scratch/>