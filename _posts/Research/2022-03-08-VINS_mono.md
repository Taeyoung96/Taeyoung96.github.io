---
title : "[Paper Review] VINS-mono 요약 및 설명"
category :
    - Research
tag :
    - Paper_Review  
    - VINS
toc : true
toc_sticky: true
comments: true
---  

Visual Inertial SLAM 중 유명한 VINS-mono를 요약해보자. [Work in Progress...]  

최근 VIO, VI-SLAM 쪽 연구를 진행하려고 하고 유명한 논문을 먼저 읽고 공부해 보고자 한다.  
Visual Inertial쪽에서 제일 인용이 많이 된 논문 중 하나인 VINS-mono를 읽어보자.  

논문은 아래 링크에서 원본을 확인할 수 있다.  

- VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator ([ArXiv](https://arxiv.org/pdf/1708.03852.pdf) , [IEEE](https://ieeexplore.ieee.org/document/8421746))      
- Github : [HKUST-Aerial-Robotics/VINS-Mono](https://github.com/HKUST-Aerial-Robotics/VINS-Mono)  

## 1. Introduction  

VINS-mono는 Monocular camera와 IMU를 결합했을 때 단순히 카메라를 썻을 때보다,   여러 장점이 있다고 소개한다.  

- Scale 값을 얻을 수 있다. (Roll, pitch angle도 얻을 수 있다.)  
- 카메라쪽에서 Tracking하기 어려운 환경(illumination change, textureless area, or motion blur)에서도 IMU 센서의 도움을 받아 Tracking을 수행할 수 있다.  
- Camera, IMU 모두 저가로 구입할 수 있는 센서이다.  

이러한 장점이 있는 반면 큰 Issue들도 존재한다.  

- 초기화 과정이 힘들다.  
> 직접 거리를 측정할 수 있는 센서가 없기 때문에, visual structure 와 inertial measurements의 결합이 어렵다.  

- VINS(visual-inertial system)은 Non-linear한 System이다.  
> 대부분의 경우 시스템은 고정 위치에서 시작해야 하며 처음에는 천천히 조심스럽게 움직여야 하므로 실제로 사용이 제한된다.  

- VIO(Visual-inertial odometry)의 경우, drift현상이 필연적이다.  

따라서 이런 Issue들을 해결하기 위해 VINS-mono에서는 다음과 같은 Contribution이 존재한다.  

- 초기 상태(initial states)를 모르더라도 초기화 할 수 있는 방법을 제안  
- Tightly coupled 방식의 sensor fusion, Optimization-based Estimation 방법  
- 실시간이 보장된 Relocalization and 4 degrees-of-freedom (DOF) global pose graph optimization  
- pose graph를 저장하고 불러오고 다른 local pose graph와 합칠 수 있음  

## 2. OverView  

Related work 부분은 생략을 할 예정이다.  

VINS-mono의 전반적인 system은 아래 그림과 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157216142-b98824d8-56d8-41a5-afe7-9f2d0e7a5760.png" width = "800" ></p>  

VINS-mono는 우선 measurement preprocessing 과정을 거친다. 이미지로부터 feature를 뽑아내고, Tracking을 하면서 연속적인 두 이미지 사이에 IMU measurments를 preintegrated하는 과정을 거친다.  

Measurement preprocessing 과정이 끝나면 초기화(initialization) 과정을 거친다. 추후 nonliear optimization을 할 때 필요한 값들을 모두 구한다. 예를 들어, pose, velocity, gravity vector, gyroscope bias, and (3-D) 특징 점의 위치 등등을 구하게 된다.  

초기화 값으로 구한 값을 가지고 Relocalization Module이 있는 Visual-Inertial Odometry Module은 preintegrated 된 IMU 측정값과, feature observations를 tightly coupeld 방법으로 fusion을 진행한다.  

VINS-mono에서는 Monocular camera와 IMU값을 이용하여 초기화하는 방법, Keyframe을 고르는 방법, tracking을 잘 수행하는 방법등을 제안했으며, Loop closure과 pose graph reuse 모듈까지 만들어 전체적인 SLAM system을 구축했다.  

이 논문에서 사용하는 Notation은 다음과 같다.  
- $()^c$ : camera frame  
- $()^w$ : world frame  
- $()^b$ : IMU frame  
- $q$ : 쿼터니언, $R$ : Rotation Matirx  
- $p$ : Translation vector  
- $b_k$ : k번째 이미지에서의 IMU(Body) frame  
- $c_k$ : k번째 이미지에서의 Camera frame  
- $\otimes$ : 쿼터니언끼리의 곱  
- $\hat{()}$ : 추정 값 or noisy measurement  

## 3. Measurement preprocessing  

Visual measurment와 IMU measurement의 전처리 과정을 자세하게 살펴보자.  

Visual measurment에서는 연속적인 이미지에서의 Tracking을 시도하고, 현재 frame에서 새로운 특징점을 찾는다. IMU measurements에서는 연속적인 두 이미지에서 preintegration과정을 거친다.  

### Vision Processing Front End  

새로운 이미지가 들어오면, KLT sparse optical flow algorithm을 수행한다. 한 이미지당 featrue의 갯수는 100개~300개 정도를 유지한다. Detector는 feature간 너무 붙어 있지 않도록 uniform feature distribution를 적용한다.  

RANSAC 알고리즘을 이용하여 Oulier 제거를 거친 후, 특징이 추출된 이미지를 unit sphere(단위 구)에 투영을 시킨다.  

이 과정에서 KeyFrame 선별도 하게 되는데 두 가지 기준을 가지고 KeyFrame을 선별한다.  

- last(최근) frame과 current(현재) frame간에 특징점들 끼리의 픽셀 차이가 일정 threshold 이상일 경우 새로운 keyframe으로 구분  
- Tracking quality에 따라 구분  

특징점 끼리의 픽셀 차이를 여기서 parallax(시차)라고 표현했다. 하지만 시차가 어떻게 정의되었는지 확인하지 못했다. 아직 이부분에 대한 이해가 조금 더 필요하다...  

Tracking quality는 이미지에서 tracked features의 수로 판별한다. 일정 Threshold를 넘길 경우, Good track으로 판별하여 새로운 KeyFrame으로 선별한다.  

### IMU pre-integration  

IMU pre-integration이란 연속적인 카메라 이미지 데이터에 IMU 정보를 결합하여 더 정교한 pose를 계산하기 위한 작업이다. 보통 아래의 그림처럼 IMU가 들어오는 간격이 카메라 이미지보다 더 빠르기 때문에 카메라 이미지 사이에 들어오는 IMU measurement들을 하나로 이미지와 싱크를 맞추는 작업을 거친다.   

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157402471-f928fb47-fe89-4586-b8fa-d1169aa14605.png" width = "500" ></p>  

IMU가 어떻게 동작하는지 우선 이해가 필요하다. 나도 이번 기회를 통해서 조금 깊게 파보려고 공부중인데 다음과 같은 링크가 도움이 되었다.  
- [[IMU] IMU의 개념 및 활용법](https://velog.io/@717lumos/Sensor-IMU%EC%9D%98-%EA%B0%9C%EB%85%90-%EB%B0%8F-%ED%99%9C%EC%9A%A9%EB%B2%95#1-%EA%B0%80%EC%86%8D%EB%8F%84-%EC%84%BC%EC%84%9C)  
- [INERTIAL NAVIGATION PRIMER](https://www.vectornav.com/resources/inertial-navigation-primer)  

기본적으로 IMU는 gyroscope(각속도)와 accelerometer(가속도)를 측정하는 센서이다. 각각의 값들은 Noise와 bias가 존재하고 VINS-mono에서는 IMU를 다음과 같이 모델링 했다.  

$a_t$는  linear acceleration 값을 나타내고, $w_t$는 angular velocity이다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157408923-863160a2-79be-44f7-afb9-7ef1e25e8b02.png" width = "400" ></p>  

각각 노이즈는 Gaussian white noise를 가정한다. 그리고 Bias값도 미분을 하게 되면 Gaussian white noise이 나오도록 모델링했다.  

[k, k+1] image frame 사이에 IMU의 translation 값 $p$, velocity 값 $v$, quaternion 값 $q$는 아래와 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157418277-2057319a-f1ea-49a8-bf3b-1e20e974393c.png" width = "500" ></p>  

여기서 $g^w$는 world 좌표계에서의 중력 값이 아닌, IMU body frame으로 투영 된 중력 값이다.  

여기서 우리는 world 좌표계가 기준이 아닌 $b_k$(k번째 이미지에서의 IMU body frame)을 기준으로 계산을 해야하므로 좌표계 변환이 필요하다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/158013605-5c51346c-1a3c-4b41-b306-c6446cc9b3b8.png" width = "500" ></p>  

따라서 결론적으로 구해야 하는 IMU의 translation 값 $$p = \alpha^{b_k}_{b_{k+1}}$$  

IMU의 velocity 값 $$v = \beta^{b_k}_{b_{k+1}}$$  

IMU의 quaternion 값 $$q = \gamma^{b_k}_{b_{k+1}}$$  

이라고 하면 아래와 같이 정리할 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/157420920-84ac9d3a-4801-4801-b12e-c2e469a8ba73.png" width = "350" ></p>  

위 수식에 대한 정리는 [Formula Derivation and Analysis of the VINS-Mono](https://arxiv.org/abs/1912.11986)에서 IMU PREINTEGRATION 파트를 보면 자세히 나와있다.  

컴퓨터는 discrite time을 가지고 있기 때문에 위에 나온 preintegration term을 discrite time에서 나타내면 식은 아래와 같다. 이때 우리는 Mid point method를 사용한다.   

$i$는 $[t_k, t_{K+1}]$에서 discrete moment를 나타낸다.  

$\delta_t$는 $i,i+1$에서의 time interval이다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/158013233-7f211e39-b41b-4838-bf88-f2164d366425.png" width = "550" ></p>  

[... 하아 일단 수식이 너무 어려움으로 나중에 다시 봐야겠다...]  

논문에 의하면 $k$번째 Image에서의 IMU measurement를 $b_k$라고 하고 $k+1$번째 Image에서의 IMU measurment를 $b_{k+1}$이라고 할 때, 그들의 관계를 나타내는 covariance $P$는 아래와 같이 나타낼 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/158014138-21ec4772-f400-4411-814f-768efb126046.png" width = "500" ></p>  

## 4. Estimator Initialization

