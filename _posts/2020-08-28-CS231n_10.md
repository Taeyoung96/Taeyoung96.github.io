---
title : "CS231n 10강 요약"
category :
    - CS231n
tag :
    - machine_learning
    - computer vision
    - CS231n
toc : true
toc_sticky: true
comments: true
---

RNN에 대해서 한 번 알아보자!

## 0. Today's Goal
> - RNN이란?
> - Image Captioning
> - LSTM


## 1. 강의 및 강의 자료

강의를 들어볼 수 있는 링크와 강의 자료를 pdf형식으로 준비했다.

- 강의 링크 : [video](https://www.youtube.com/watch?v=6niqTuYFZLQ&t=0s)

- 강의 슬라이드 : [슬라이드](https://github.com/Taeyoung96/Taeyoung96.github.io/files/5156225/cs231n_2017_lecture10.pdf)

한글 자막이 필요하신 분은 다음의 링크를 확인해주세요. :)

- 한글 자막을 첨부하고 싶으면 [여기](https://github.com/visionNoob/CS231N_17_KOR_SUB)를 눌러주세요.

## 2. RNN이란?

RNN이란 Recurrent Neural Network의 줄임말로  
지금까지 우리가 배운 CNN 구조와는 살짝 다른 모델 구조를 갖는다.  

지금까지 우리가 배운 구조를 **"Vanilla" Neural Network**라고 하자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91852834-54cd1080-ec9c-11ea-8cb7-97c142144a6d.png" width = "300" ></p>

입력이 하나 들어가고, 출력이 하나 나오는 형태로 hidden layer를 거쳐서 하나의 output 형태로 나오는 것을 주로 배웠다.  

하지만, 만약 입 / 출력의 갯수가 변하면 어떻게 될까?

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91853042-98277f00-ec9c-11ea-940a-e25e2581a1bf.png" width = "500" ></p>

이처럼 다양한 입 / 출력을 다룰 수 있도록 만든 모델이 **RNN**이다.  

예를 들어, 'one to many'의 같은 경우는 **Image Captioning**이 될 수 있고,  
'many to one'의 경우는 **Sentiment Classification**이 될 수 있고,  
'many to many'인 경우는 **Machine Translation**이나 **Video classification on frame level**의 경우가 될 수 있다.  

입 / 출력이 단일이더라도, 찾는 과정을 가변과정으로 찾게 되면 RNN을 사용할 수 있다.

그렇다면 RNN의 흐름은 어떻게 될까?
> 1. 입력을 받는다.
> 2. 모든 step마다 Hidden state를 update 한다.
> 3. 출력 값을 내보낸다.

일반적인 CNN의 흐름과 비슷한 것(?) 같다.

그림을 통해 다시 한 번 알아보자.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91854495-c8701d00-ec9e-11ea-857f-7e8f798cddde.png" width = "500" ></p>

매 step마다 $x_t$가 들어오고 기존에 있던 $h_{t-1}$를 가지고, $h_t$를 update한다.

이 모델에서 알아야 할 것은 **같은 set의 parameter들을 가지고 매 step마다 update를 진행한다는 것이다.**

방금 설명한 부분을 식으로 나타내면,  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91855296-f30ea580-ec9f-11ea-9c88-bddb857d1ffa.png" width = "300" ></p>

여기서 비선형성을 위해 $tanh$ 함수를 사용한다.  

---

RNN의 Computational Graph를 한 번 알아보자.  

처음의 $h_0$는 대부분 0으로 초기화 한다.  
출력인 $h_1$가 다음에는 입력으로 들어가는 모습을 볼 수 있다.  

또 다른 $x_2$를 받아 다시 출력으로 $h_2$를 만들어 낸다.

이 과정을 무한반복한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91857010-45e95c80-eca2-11ea-92d8-b00c5630a524.png" width = "500" ></p>

아까 언급했다시피 똑같은 set의 parameter를 가지고 update를 진행하는 것을 볼 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91856908-22261680-eca2-11ea-85b6-cf082668117b.png" width = "500" ></p>

만약 출력이 다수라면 'many to many' 분류할 수 있고,  
그에 대한 Loss function도 많다는 것을 알 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91857201-8fd24280-eca2-11ea-848c-41e12102e4f8.png" width = "500" ></p>

또 다른 예로 입력이 하나이고, 출력이 다수라면 Computational graph는 다음과 같이 나타낼 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91857681-2b63b300-eca3-11ea-87a7-a8e0c55a6adf.png" width = "500" ></p>

이제 Character-level language Model를 통해 RNN을 좀 더 이해해보자.  

쉽게 말해 문자열 시퀀스를 입력으로 받아서 다음 문자를 예측하는 모델을 말한다.  

예를 들어 [h,e,l,o]라는 문자열 시퀀스가 있고,  
내가 "hello"라는 문자열을 만들고 싶다고 하자.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91858000-9e6d2980-eca3-11ea-89cb-7f285c7ba4c2.png" width = "400" ></p>

먼저 Input 문자를 4d 벡터로 만든 다음  
$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$
윗 식을 이용하여 hidden layer의 값을 구해준다.  

여기서도 $W_{hh}$와 $W_{xh}$는 모두 같은 값을 사용한다.  

그 다음 target chars를 고를 때는 확률 분포에서 샘플링을 진행한 후,  
다음 Input chars로 넣어줄 문자를 골라준다.  

이렇게 하는 이유는 Softmax에서 가장 높은 값이 나온 문자가 우리가 원하는 문자가 아닐 수 있기 때문이다!  

이러한 모델을 train을 하려면 어떻게 될까?

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91861467-cb234000-eca7-11ea-9c9a-f90b5ea0a6bc.png" width = "500" ></p>

하나의 출력값을 알기 위해서 처음부터 모든 Loss 값들을 알아야 한다..  
이렇게 되면 계산량이 어마어마해진다.  

따라서 실제로 사용하는 방법은 다음과 같다.  

train 할 때 한 스텝을 일정 단위로 나눈 후, 서브시퀀스의 Loss들만 계산한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91861770-2a815000-eca8-11ea-80a2-583650ba0fdf.png" width = "400" ></p>

---

RNN은 여러 분야에서 활용될 수 있다.  

여기서 발견한 신기한 점은 **다음 문자가 어떤 것이 나올지 예측하는 모델을 만들었는데, 이 모델은 전체적인 문장 구조를 파악해서 알아서 그 구조를 학습한다는 점**이다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91862252-ad0a0f80-eca8-11ea-8ea8-5b5577fcb69f.png" width = "500" ></p>

<center> RNN을 이용하여 Latex source를 학습한 모습 </center>
<br>

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91862432-e478bc00-eca8-11ea-987d-8b6a7a20a0f1.png" width = "500" ></p>

<center> RNN을 이용하여 C code를 학습한 모습 </center>
<br>

물론 증명이 안되는 수식들과 컴파일도 안되는 엉망인 코드를  적어놓았지만 그래도 이런 틀을 학습했다는 것이 매우 놀랍다..!

## 3. Image Captioning

Image Captioning이란 <u>하나의 사진을 보고 이 사진이 무엇인지 설명하는 문장을 만들어 내는 딥러닝 모델</u>을 말한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91862820-649f2180-eca9-11ea-9d50-bccb2d780553.png" width = "500" ></p>

사진을 보고 CNN 구조를 통과한 결과가  
RNN의 입력으로 들어가는 모습을 볼 수 있다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91863273-e8590e00-eca9-11ea-9c22-f6a1b928af78.png" width = "500" ></p>

실제로 test Image가 들어가게 되면  
Softmax를 통과하기 바로 전 Fully Connected Layer를 이용한다.  

새로운 가중치 행렬을 추가하여 이미지 정보를 추가해준다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91863882-8cdb5000-ecaa-11ea-903f-8b71870c3e82.png" width = "500" ></p>

그리고 RNN 구조를 이용하여 문자열 결과를 출력해준다.  

Image Captioning의 여러 예들을 살펴보면

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91863992-b1cfc300-ecaa-11ea-8249-76a0da74ce4d.png" width = "500" ></p>

물론 이런 결과는 모두 **Supervised Learning**이다.  

---

조금 더 진보된 모델인 **Image Captioning with Attention**를 살펴보자.  

Input Image를 통해 공간 정보를 담고 있는 Grid of Vector 값을 얻어낸다.  
내가 이해하기론 Feature Map과 비슷한 개념이라 생각한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91864303-05daa780-ecab-11ea-86cb-ede468681c27.png" width = "400" ></p>

그 다음 Output을 살펴보면 총 2가지의 출력이 있다는 것을 알 수 있다.  

> - 이미지에서 어느 부분을 집중적으로 보았는지? (이미지 분포)
> - 단어의 분포는 어떻게 되는지? (단어의 분포)


<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91866096-168c1d00-ecad-11ea-8e7a-23e4c70ca1da.png" width = "500" ></p>

그림에서 a1, a2 등이 이미지의 분포를 나타낸 출력값,  
d1, d2 등이 단어의 분포를 나타낸 출력값이다.  

z는 다음과 같은 수식을 통해 만들어진다.  

$z = \sum^L_{i=1} p_iv_i$

a1의 결과와 Feature의 결과를 곱해서 z를 표현하게 됩니다. 

**Image Captioning with Attention**과정을 시각화하면  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91866772-d2e5e300-ecad-11ea-8d0b-31663dfc5e0b.png" width = "500" ></p>

모델의 caption을 생성하기 위해 이미지의 attention을 이동하는 모습을 볼 수 있다.  

즉, 의미가 있다고 생각하는 부분에 스스로 attention을 집중하는 모습을 보인다.  

---

이와 비슷한 Task로 **VQA(Visual Question Answering)**이라는 일이 있다.  

이미지와 질문을 동시에 던졌을 때, 답을 맞추는 과정을 말한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91867046-235d4080-ecae-11ea-8927-cf488953ba0b.png" width = "500" ></p>

이러한 Task 역시 RNN을 통해서 학습을 할 수 있다.  

모델이 깊어질 수록 다양한 문제들에 대해서 성능이 더 좋아지는 것을 확인할 수 있다.  

Train을 하기 위해서 Gradient값을 구해야 하는데,

먼저 Vanilla RNN Gradient Flow를 살펴보면

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91867655-d9c12580-ecae-11ea-89a6-60660c143036.png" width = "500" ></p>

RNN 하나의 cell을 통과할 때 마다 가중치 행렬의 일부를 곱하게 되는 모습을 볼 수 있다.  

하나의 cell이 아닌 전체적인 cell로 gradient를 구하는 모습을 살펴보면

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91868178-6cfa5b00-ecaf-11ea-90ca-fecd92240317.png" width = "500" ></p>

많은 W 행렬들이 개입하게 되어 계산량이 늘어나는 것을 확인할 수 있다.  

그리고 또 하나의 문제점이 생기는데  

Weight 행렬에서 특이값의 최대값에 따라 Gradient값이 폭발적으로 증가할 수도, 너무 작게 감소할 수도 있는 문제점이 발생한다.  

이러한 문제점을 해결하기 위해 나온 새로운 RNN 구조가 있는데,  

그것이 바로 **LSTM**이다.  

## 4. LSTM

LSTM이란 Long Short Term Memory에 약자로 RNN의 새로운 구조 중 하나이다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91868959-47218600-ecb0-11ea-956e-bb5116e7ad0e.png" width = "500" ></p>

기본적인 RNN 구조와 비교를 해보면,  
LSTM은 두개의 hidden state가 존재하고 $c_t$라는 내부에만 존재하는 변수가 존재한다.  

위 그림에서 보이는 $\sigma$ 함수는 Sigmoid를 뜻한다.

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91869299-b008fe00-ecb0-11ea-8386-7a2798636cc6.png" width = "500" ></p>

좀 더 자세히 LSTM을 살펴보자.  
총 4가지의 gate가 있다고 생각할 수 있다.  

> - i - Input gate : cell에 대한 입력 ($x_t$에 대한 가중치)
> - f - Forget gate : 이전 cell에 대한 정보를 얼마나 지울 것인가?
> - o - Output gate : $c_t$를 얼마나 밖으로 드러낼 것인가?
> - g - Gate gate(?) : Cell을 얼마나 포함 시킬 것인지?

LSTM에 대한 Flow chart는 다음과 같다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91869757-36254480-ecb1-11ea-9e7a-ccb01550d059.png" width = "400" ></p>

여기서 Gradient Flow 과정을 살펴보면  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91869866-57863080-ecb1-11ea-8f43-5013504a79a4.png" width = "400" ></p>

하나의 cell에서 Weight행렬을 거치지 않고도 cell 단위에서 gradient 계산을 할 수 있다.  

여러 cell을 거치더라도 계산량이 크게 증가하지 않는다는 것을 알 수 있다.


즉, forget gate와 곱해지는 연산이 행렬 단위의 곱셈 연산이 아니라 element-wise (원소별 연산)이기 때문에 계산량이 크게 증가하지 않는다.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91870261-cbc0d400-ecb1-11ea-9365-4fc88b3384c4.png" width = "500" ></p>

마치 CNN의 ResNet 구조와 비슷하게 생겼다..  

여러 RNN 구조 중에서 GRU라는 구조가 있는데,  
이건 그냥 이런게 있구나 하고 넘어가자...ㅎ

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/91870619-fb6fdc00-ecb1-11ea-8b92-e199c527faec.png" width = "500" ></p>

신기하긴 하지만 RNN이라는 개념 자체가 좀 어려운 것 같다...

이렇게 RNN에 대한 요약을 마무리해본다.
